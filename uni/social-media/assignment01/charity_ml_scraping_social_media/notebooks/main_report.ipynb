{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### COSC2671 Social Media and Network Analytics\n",
    "#### Assignment 1\n",
    "@author Phil Steinke, 2019\n",
    "Due 30 August/ 2019\n",
    "\n",
    "15 marks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "TODO: Introduction\n",
    "\t•\tDescribe what/who is your selected entity\n",
    "\t•\tDescribe why it is interesting to find the sentiment and topics (answer questions) of this entity\n",
    "    Goal:\n",
    "        What are the trending concepts and topics associated with this person or event?\n",
    "        • What are the perceptions and feelings towards this person or event?\n",
    "- [ ] Get Twitter data\n",
    "- [ ] Do market research\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# packages\n",
    "# python scripts\n",
    "import os\n",
    "from src.config.constants import Constants\n",
    "os.chdir(Constants.path)\n",
    "from src.common.util import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "TODO: Data Collection\n",
    "\t•\tDescribe how you collected the data, and briefly why you chose that approach (restful vs stream)\n",
    "\t•\tReport some statistics of your collected data\n",
    "0. Setup\n",
    "- [x] a few thousand tweets per week in your data.\n",
    "Initially, we searched for multiple terms with the search: \n",
    "\"charity\" (data OR science OR artificial OR intelligence OR machine OR learning OR ai OR ml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# TODO: for charity, machine learning, etc\n",
    "# params\n",
    "# start_date = '2018-08-01'\n",
    "from src.data.api import *\n",
    "\n",
    "start_date = '2018-08-01'\n",
    "# search_term = '\"charity\"%20(machintodo1e%20OR%20learning%20OR%20artificial%20OR%20intelligence)%20(%23ml%20OR%20%23ai)'\n",
    "# NOTE: only run this once\n",
    "fetchTweets(search_term, start_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can refine it to charity:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "search_term = 'charity'\n",
    "# NOTE: only run this once\n",
    "fetchTweets(search_term, start_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Obstacles:\n",
    "- Text is trunicated\n",
    "wrote function `handle_fulltext_twitter_json_loc(tweet)` to deal with getting full text from \n",
    "tweets. Because `full_text` is present in a different location in the json for \n",
    "retweets and regular tweets\n",
    "see: http://docs.tweepy.org/en/latest/extended_tweets.html#examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Data Pre-processing \n",
    "\n",
    "TODO: Pre-processing and Data Cleaning\n",
    "\t•\tDescribe  what pre-processing you performed\n",
    "\t•\tShow examples of noisy data, plot some graphs, etc to show why you decided to do those pre-processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from src.preprocessing import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert CSV to json\n",
    "Initially I scraped into a CSV, so this code converts it into json format:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "colnames=['full_text', 'date', 'id'] \n",
    "convert_csv_to_json('data/raw/charity_tweets_heaps_11110', colnames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1.1 Data Cleaning (Pre-processing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Sample tweet\n",
    "Lets grab a sample tweet:\n",
    "From the scraper we get:\n",
    "\n",
    "> 'b\"don\\'t use just #artificialintelligence for the sake of it. #AI needs to solve a problem - @somenmondal @ideal What kind of problems could #AI solve in your #charity? https://t.co/BaO22oyQDW\"'\n",
    "\n",
    "We want:\n",
    "> don't use just artificialintelligence for the sake of it. AI needs to solve a problem - What kind of problems could AI solve in your charity?\n",
    "\n",
    "What we need to do:\n",
    "- Each of the tweets when we get the full_text tweet starts with `b'`\n",
    "Initially, this appears as byte data, however, it's actually a string\n",
    "- [ ] Each tweet starts with 'b\"\n",
    "- [ ] Special characters are \\\\xf0\\\\x9f\\\\xa4\\\\x96, etc and escaped\n",
    "- [ ] Remove links\n",
    "- [ ] Remove @usernames\n",
    "- [ ] Remove #hashtags\n",
    "\n",
    "FIXME: do I need this bit?\n",
    "df.head()\n",
    "\n",
    "df = pd.DataFrame(df,columns=['text',  'date',  'user_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# FIXME: df = 'data/raw/charity_tweets_heaps_11110.json'\n",
    "fJsonName = 'data/raw/charity_tweets_heaps_sample_100.json'\n",
    "\n",
    "import json\n",
    "from io import open\n",
    "import pandas as pd\n",
    "\n",
    "from src.preprocessing import strip_twitter_special_characters\n",
    "\n",
    "# why do we need to decode it again to utf8?\n",
    "# grab a part of our encoded text:\n",
    "encoded_sample = b'didn\\xe2\\x80\\x99t'\n",
    "# type(encoded_sample) # bytes\n",
    "# however, the type(tweet) # string of our tweet\n",
    "b'didn\\xe2\\x80\\x99t'.decode('utf-8') # output is `didn't`\n",
    "# So formatting it to utf-8 works\n",
    "\n",
    "# LATER: move to preprocessing function\n",
    "def decode_byte_to_string(tweet):\n",
    "    # deal with tweet full text\n",
    "    tweet_text_wrong_datatype = tweet.get('full_text', '')\n",
    "    # HACK: because it imports as string, however, it is a byte:\n",
    "    tweet_text_bytes = eval(tweet_text_wrong_datatype.encode('ascii', 'ignore').decode('utf8'))\n",
    "    tweet_text_string = tweet_text_bytes.decode('utf8')\n",
    "    return(tweet_text_string)\n",
    "\n",
    "with open(fJsonName) as f:\n",
    "    tweets_proccessed = []\n",
    "\n",
    "    for line in f:\n",
    "        tweet = json.loads(line)\n",
    "\n",
    "        tweet_text_string = decode_byte_to_string(tweet)\n",
    "        stripped = strip_twitter_special_characters(tweet_text_string)\n",
    "\n",
    "        # append the stripped text to our json as tweets_proccessed\n",
    "        tweet.update({'full_text_stripped' : stripped})\n",
    "\n",
    "        # BUG: doesn't work:\n",
    "        # with open('data/processed/data.json', 'w') as outfile:\n",
    "        #     f.write(json.dump(tweet, outfile)) \n",
    "            \n",
    "        tweets_proccessed.append(tweet)\n",
    "                \n",
    "    f.close()\n",
    "\n",
    "with open('data/processed/data.json', 'w') as outfile:\n",
    "    json.dump(tweets_proccessed, outfile)\n",
    "\n",
    "# ---\n",
    "\n",
    "# LATER:\n",
    "# cols = ['tweet']\n",
    "# df = pd.DataFrame(tweets, columns=cols)    \n",
    "\n",
    "# Done:\n",
    "# - [x] Each tweet starts with 'b\"\n",
    "# - [x] Special characters removed are \\\\xf0\\\\x9f\\\\xa4\\\\x96, etc and escaped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from src.preprocessing import strip_twitter_special_characters\n",
    "# original tweet:\n",
    "# FIXME: Update to our own sample\n",
    "# ### Remove unnecessary text\n",
    "# Function to remove @username, #hashtags, links, and underscores using regex:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "test_tweet = df.iloc[1,0]\n",
    "print(test_tweet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Demo the stripper:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# FIXME: add tweets list again\n",
    "\n",
    "stripped_tweets = strip_twitter_special_characters(tweets)\n",
    "stripped_tweets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Done: \n",
    "\n",
    "- [x] Remove links\n",
    "- [x] Remove @usernames\n",
    "- [x] Remove #hashtags\n",
    "\n",
    "Note for later:\n",
    "It would be great to analyse rather than remove emojis\n",
    "\n",
    "NOTE: https://towardsdatascience.com/5-methods-to-remove-the-from-your-data-in-python-and-the-fastest-one-281489382455\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "TODO: Analysis Approach\n",
    "\t•\tDescribe what analysis you performed to answer the questions\n",
    "\t•\tWhat type of sentiment analysis did you do?  Briefly explain your rationale for doing it as such.\n",
    "\t•\tWhat type of topic modelling did you do?  Again, briefly explain your rationale for your approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1.2 Initial Exploration (Pre-processing)\n",
    "\n",
    "- [ ] number of tweets, \n",
    "- [ ] top K unique hashtags\n",
    "\n",
    "- [x] Are there characters that aren't useful for analysis\n",
    "Removed above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# # - [ ] Top K unique words\n",
    "from src.features import *\n",
    "\n",
    "doProcessTweet('data/processed/data.json', 'full_text_stripped', 30)\n",
    "\n",
    "# BUG: doGetHashtags('data/processed/data.json', 30)\n",
    "# BUG: doGetMentions('data/processed/data.json', 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Analysis Methodology\n",
    "\n",
    "### Initial Analysis\n",
    "\n",
    "### Does the approach selected have parameters\n",
    "\n",
    "Not particularly\n",
    "\n",
    "### Would a different approach produce different answer?\n",
    "A: Yes. Given _more_ time I would have a look at combinations of two \n",
    "or multiple word groups of sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.1 Selection and Parameter choices (Methodology)\n",
    "\n",
    "### What effect does the parameter settings have on the results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.1 Justify parameters with explanations (Methodology)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Analysis & Discussion\n",
    "\n",
    "- what are the topics been discussed about a user via a top-K terms\n",
    "- word-cloud of the topics discovered by topic modelling\n",
    "- what are the topics\n",
    "- does it correspond to recent news\n",
    "A: Given the heart foundations recent (controversy)[https://www.abc.net.au/news/2019-05-31/heart-foundation-apologises-for-heartless-words-ad-campaign/11167870]\n",
    "I became interested in how people feel about charities.\n",
    "Eg. Are people generally positive about charity? Or do they have 'compassion\n",
    "fatigue'? Can organisations like the Heart foundation justify shocking people\n",
    "into doing what they want?\n",
    "- other sources of information\n",
    "- if the results don’t correspond to background knowledge, why you think that is so?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "TODO: Conclusion\n",
    " •\tProvide a short conclusion about your entity, analysis and what you found\n",
    "\n",
    "### Discussion of results (Discussion)\n",
    "\n",
    "- Describe your data\n",
    "- Outline and describe your approach, your findings and insights to the questions\n",
    "- Use tables, plots/graphs, word clouds and other visualisations to help you communicate the results (in addition to text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Explain what the results indicate (Discussion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Other Rubric\n",
    "- [ ] Report Presentation 15%\n",
    "- [ ] Code Style and Readability\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Sample of the Data (1st 1000 tweets, embed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Bibleography\n",
    "\n",
    "- Use citethisforme tool\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
