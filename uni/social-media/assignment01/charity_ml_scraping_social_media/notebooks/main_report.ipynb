{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## COSC2671 Social Media and Network Analytics\n",
        "### Assignment 1\n",
        "@author Phil Steinke, 2019\n",
        "15 marks\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "TODO: Introduction\n",
        "\n",
        "All code chunks are available on [github](https://github.com/tgrrr/data-science/tree/social-media-assignment1/uni/social-media/assignment01)\n",
        "- Describe what/who is your selected entity\n",
        "I'm searching for sentiment analysis about the topic `Charity` on Twitter\n",
        "\n",
        "- Describe why it is interesting to find the sentiment and topics \n",
        "(answer questions) of this entity\n",
        "A: Given the heart foundations recent \n",
        "(controversy)[https://www.abc.net.au/news/2019-05-31/heart-foundation-apologises-for-heartless-words-ad-campaign/11167870]\n",
        "I became interested in how people feel about charities.\n",
        "Eg. Are people generally positive about charity? Or do they have 'compassion\n",
        "fatigue'? Can organisations like the Heart foundation justify shocking people\n",
        "into doing what they want?\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# packages\n",
        "# python scripts\n",
        "import os\n",
        "import pdb\n",
        "from src.config.constants import Constants\n",
        "os.chdir(Constants.path)\n",
        "from src.common.util import *\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "TODO: 0. Data Collection\n",
        "- [ ] Describe how you collected the data, and briefly why you chose that approach (restful vs stream)\n",
        "- [ ] Report some statistics of your collected data\n",
        "- [x] A few thousand tweets per week in your data.\n",
        "Initially, we searched for multiple terms with the search term: \n",
        "\"charity\" (data OR science OR artificial OR intelligence OR machine OR learning OR ai OR ml)\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from src.data.api import *\n",
        "\n",
        "# params:\n",
        "start_date = '2018-08-01'\n",
        "search_term = '\"charity\"%20(machintodo1e%20OR%20learning%20OR%20artificial%20OR%20intelligence)%20(%23ml%20OR%20%23ai)'\n",
        "fetchTweets(search_term, start_date)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we can refine it to charity:\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "search_term = 'charity'\n",
        "# NOTE: only run this once, it's an expensive function\n",
        "fetchTweets(search_term, start_date)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Obstacles:\n",
        "- Text is trunicated\n",
        "Solution: wrote function `handle_fulltext_twitter_json_loc(tweet)` to deal \n",
        "with getting full text from tweets. Because `full_text` is present in a \n",
        "different location in the json for retweets and regular tweets\n",
        "see: http://docs.tweepy.org/en/latest/extended_tweets.html#examples\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 1. Data Pre-processing \n",
        "\n",
        "TODO: Pre-processing and Data Cleaning\n",
        "- [ ] Describe what pre-processing you performed\n",
        "- [ ] Show examples of noisy data, plot some graphs, \n",
        "etc to show why you decided to do those pre-processing\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from src.preprocessing import *\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert CSV to json\n",
        "Initially I scraped into a CSV, so this code converts it into json format:\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 1.1 Data Cleaning (Pre-processing)\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "colnames=['full_text', 'date', 'id'] \n",
        "convert_csv_to_json('data/raw/charity_tweets_heaps_11110', colnames)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Sample tweet\n",
        "Lets grab a sample tweet:\n",
        "From the scraper we get:\n",
        "\n",
        "> 'b\"don\\'t use just #artificialintelligence for the sake of it. #AI needs to solve a problem - @somenmondal @ideal What kind of problems could #AI solve in your #charity? https://t.co/BaO22oyQDW\"'\n",
        "\n",
        "We want:\n",
        "> don't use just artificialintelligence for the sake of it. AI needs to solve a problem - What kind of problems could AI solve in your charity?\n",
        "\n",
        "What we need to do:\n",
        "- Each of the tweets when we get the full_text tweet starts with `b'`\n",
        "Initially, this appears as byte data, however, it's actually a string\n",
        "- [ ] Each tweet starts with 'b\"\n",
        "- [ ] Special characters are \\\\xf0\\\\x9f\\\\xa4\\\\x96, etc and escaped\n",
        "- [ ] Remove links\n",
        "- [ ] Remove @usernames\n",
        "- [ ] Remove #hashtags\n",
        "\n",
        "FIXME: do I need this bit?\n",
        "df.head()\n",
        "\n",
        "df = pd.DataFrame(df,columns=['text',  'date',  'user_id'])\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# FIXME: df = 'data/raw/charity_tweets_heaps_11110.json'\n",
        "\n",
        "from src.preprocessing import *\n",
        "\n",
        "# why do we need to decode it again to utf8?\n",
        "# grab a part of our encoded text:\n",
        "encoded_sample = b'didn\\xe2\\x80\\x99t'\n",
        "# type(encoded_sample) # bytes\n",
        "# however, the type(tweet) # string of our tweet\n",
        "b'didn\\xe2\\x80\\x99t'.decode('utf-8') # output is `didn't`\n",
        "# So formatting it to utf-8 works\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to remove @username, #hashtags, links, underscores, and escaped char\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "fJsonName = 'data/raw/charity_tweets_heaps_sample_100.json'\n",
        "out = 'data/processed/data_sample.json'\n",
        "strip_tweet(fJsonName, out)\n",
        "\n",
        "fJsonName = 'data/raw/charity_tweets_heaps_11110.json'\n",
        "out = 'data/processed/data.json'\n",
        "strip_tweet(fJsonName, out)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Demo stripping:\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "test_tweets = [\n",
        "    \"b\\The * Mooch*...apt nickname...you're not truthful so it's doubtful the * proceeds * go to any charity that isn't an LLC for *Mooch's Piggy Bank*... https://t.co/YA9pey2ljW\",\n",
        "    \"b\\FBI eyes Jones' charity, UAW officials' California junkets https://t.co/iQfIjLCyxL\",\n",
        "    \"b\\@johnpavlovitz @2LarryJohnson7 I hope Larry Johnson boxes you for charity.\",\n",
        "    \"b\\#TheBiblicalStandard it's only the HONORABLE MESSIAH who will help the church to reach the Bibilical standards. HE offered the Sarcrifice of attonment outside the gate on a tree for you and me to see GOD face to face.Uuuuuuuuii this is greater love.\"\n",
        "]\n",
        "\n",
        "cols = ['tweet']\n",
        "df = pd.DataFrame(tweets, columns=cols)\n",
        "\n",
        "test_tweet = df.iloc[1,0]\n",
        "print(test_tweet)\n",
        "# test_tweet = \"b\\The * Mooch*...apt nickname...you're not truthful so it's doubtful the * proceeds * go to any charity that isn't an LLC for *Mooch's Piggy Bank*... https://t.co/YA9pey2ljW\"\n",
        "\n",
        "# FIXME: for demo. This works in the test dataset\n",
        "stripped_tweet = do_strip_tweet(test_tweet)\n",
        "stripped_tweet"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save as dataframe\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Done: \n",
        "- [x] Each tweet starts with 'b\"\n",
        "- [x] Special characters removed are \\\\xf0\\\\x9f\\\\xa4\\\\x96, etc and escaped\n",
        "- [x] Remove links\n",
        "- [x] Remove @usernames\n",
        "- [x] Remove #hashtags\n",
        "\n",
        "Note for later:\n",
        "It would be great to analyse rather than remove emojis\n",
        "NOTE: https://towardsdatascience.com/5-methods-to-remove-the-from-your-data-in-python-and-the-fastest-one-281489382455\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "TODO: Analysis Approach\n",
        "- [ ] Describe what analysis you performed to answer the questions\n",
        "- [ ] What type of sentiment analysis did you do?  Briefly explain your rationale for doing it as such.\n",
        "- [ ] What type of topic modelling did you do?  Again, briefly explain your rationale for your approach.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 1.2 Initial Exploration (Pre-processing)\n",
        "\n",
        "- [ ] number of tweets, \n",
        "- [ ] top K unique hashtags\n",
        "- [x] Are there characters that aren't useful for analysis\n",
        "Removed above\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# # - [ ] Top K unique words\n",
        "from src.features import *\n",
        "from src.preprocessing import *\n",
        "# from src.common.util import *\n",
        "\n",
        "\n",
        "# doProcessTweet('data/processed/data.json', 'full_text_stripped', 30)\n",
        "doProcessTweet('data/processed/data.json', 'full_text_stripped', 30, isJson=True)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: scrape it again, with hashtags and mentions\n",
        "BUG: doGetHashtags('data/processed/data.json', 30)\n",
        "BUG: doGetMentions('data/processed/data.json', 30)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 2. Analysis Methodology\n",
        "\n",
        "### Initial Analysis\n",
        "\n",
        "### Does the approach selected have parameters\n",
        "\n",
        "A: Not particularly\n",
        "\n",
        "### Would a different approach produce different answer?\n",
        "A: Yes. Given _more_ time I would have a look at combinations of two \n",
        "or multiple word groups of sentences\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 2.1 Selection and Parameter choices (Methodology)\n",
        "\n",
        "### What effect does the parameter settings have on the results?\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 2.1 Justify parameters with explanations (Methodology)\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Analysis & Discussion\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- what are the topics been discussed about a user via a top-K terms\n",
        "\n",
        "charities: 8703\n",
        "this: 1902\n",
        "raise: 1803\n",
        "donate: 1769\n",
        "money: 1440\n",
        "ha: 1390 TODO:\n",
        "help: 1309\n",
        "support: 1253\n",
        "world: 1221\n",
        "hi: 1121\n",
        "amp: 969\n",
        "ever: 938\n",
        "wa: 897 TODO:\n",
        "watch: 852\n",
        "create: 815\n",
        "people: 797\n",
        "day: 788\n",
        "clean: 768\n",
        "porn: 758\n",
        "ocean: 748\n",
        "dirtiest: 744\n",
        "thanks: 707\n",
        "work: 701\n",
        "us: 691\n",
        "get: 686\n",
        "go: 663\n",
        "one: 654\n",
        "year: 651\n",
        "please: 631\n",
        "\n",
        "- what are the topics\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from src.visualization import *\n",
        "from src.data import *\n",
        "lTweets_sample = load_tweets_list('data/processed/data_sample.json')\n",
        "doDisplayWordcloud(lTweets_sample)\n",
        "\n",
        "lTweets = load_tweets_list('data/processed/data.json')\n",
        "doDisplayWordcloud(lTweets)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Cloud\n",
        "\n",
        "- [x] word-cloud of the topics discovered by topic modelling\n",
        "\n",
        "> **Topic 0:** charity new today work amp support event help local great helping looking need challenge charities\n",
        "> **Topic 1:** like shop charity good month people luck yes life fantastic time 50 thank end receive\n",
        "> **Topic 2:** charity match proceeds funds final organisations 16 hate million dedicated held alongside stadium distributed combatting\n",
        "> **Topic 3:** charity amp donate amazing just year don ve make people going uk time aid great\n",
        "> **Topic 4:** president charity donating 10 000 donate project help campaign let trump salary rich known vets\n",
        "> **Topic 5:** charity raised donations world did million tour sell massive 29 harry 90 seconds styles years\n",
        "> **Topic 6:** cancer charity want people support thank help link use saturday research way thanks august donated\n",
        "> **Topic 7:** charity day september raising love team 2019 golf health community amp does know days family\n",
        "> **Topic 8:** porn charity money raise world watch created clean dirtiest oceans home follow begins doesn girl\n",
        "> **Topic 9:** charity money god heart like government taking jesus think doing amp head isn shops good\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# from src.models import *\n",
        "from src.models import *\n",
        "doSentimentAnalysis('data/processed/data_sample-multi-json.json')\n",
        "# Note: I added senti\n",
        "\n",
        "\n",
        "'reports/figures/charity_sentiment_analysis_timeseries.png'\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# - [x] Does it correspond to recent news\n",
        "# A: Given the heart foundations recent \n",
        "# (controversy)[https://www.abc.net.au/news/2019-05-31/heart-foundation-apologises-for-heartless-words-ad-campaign/11167870]\n",
        "# I became interested in how people feel about charities.\n",
        "# Eg. Are people generally positive about charity? Or do they have 'compassion\n",
        "# fatigue'? Can organisations like the Heart foundation justify shocking people\n",
        "# into doing what they want?\n",
        "# - [x] other sources of information\n",
        "# See comments about Red Cross above\n",
        "# - [x]  if the results don’t correspond to background knowledge, why you think that is so?\n",
        "# It corresponds to my background knowledge\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "TODO: ### Conclusion\n",
        " •\tProvide a short conclusion about your entity, analysis and what you found\n",
        "### Discussion of results (Discussion)\n",
        "\n",
        "- Describe your data\n",
        "- Outline and describe your approach, your findings and insights to the questions\n",
        "- Use tables, plots/graphs, word clouds and other visualisations to help you communicate the results (in addition to text\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Explain what the results indicate (Discussion)\n",
        "\n",
        "### Goals:\n",
        "- [x] What are the trending concepts and topics associated with this person or event?\n",
        "- [x] What are the perceptions and feelings towards this person or event?\n",
        "- [x] Get Twitter data\n",
        "- [x] Do market research\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Sample of the Data (1st 1000 tweets, embed)\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Bibleography\n",
        "\n",
        "- Use citethisforme tool\n",
        "\n"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "argv": [
        "/Users/phil/.pyenv/versions/py36/bin/python3",
        "-m",
        "ipykernel_launcher",
        "-f",
        "{connection_file}"
      ],
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}